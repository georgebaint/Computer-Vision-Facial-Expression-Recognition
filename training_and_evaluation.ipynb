{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset class for FER2013\n",
    "class TensorFromDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_name = self.data.iloc[idx, 1]\n",
    "        pixels = [int(pixel) for pixel in img_name.split(' ')]\n",
    "        image = torch.tensor(pixels, dtype=torch.float32).reshape(48, 48)\n",
    "\n",
    "        label = int(self.data.iloc[idx, 0])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# # Define transformations for preprocessing\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.Grayscale(num_output_channels=1),\n",
    "#     transforms.Resize((64, 64)),  # Resize the images to match model input size\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5,), (0.5,))\n",
    "# ])\n",
    "# transform = None\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "df = pd.read_csv('fer2013/fer2013/fer2013.csv')\n",
    "training = df[df['Usage'] == 'Training']\n",
    "validation = df[df['Usage'] == 'PublicTest']\n",
    "testing = df[df['Usage'] == 'PrivateTest']\n",
    "\n",
    "# Load FER2013 dataset\n",
    "\n",
    "train_set = TensorFromDataset(data = training, transform=transform)\n",
    "valid_set = TensorFromDataset(data = validation, transform=transform)\n",
    "test_set = TensorFromDataset(data = testing, transform=transform)\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "data_loader_train = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "data_loader_validation = DataLoader(valid_set, batch_size=batch_size, shuffle=True)\n",
    "data_loader_test = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x00000283C97AD610>\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(loader):\n",
    "    # Create a DataLoader for the dataset\n",
    "    # loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize lists to store the features and labels\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through the DataLoader\n",
    "    for imgs, lbls in loader:\n",
    "        # Depending on your model, you might want to move your tensors to a device like CUDA\n",
    "        imgs, lbls = imgs.cuda(), lbls.cuda()\n",
    "        \n",
    "        # Append the batch to the lists\n",
    "        features.append(imgs)\n",
    "        labels.append(lbls)\n",
    "\n",
    "    # Concatenate all batches\n",
    "    features = torch.cat(features, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, you can use this function to split your test_set\n",
    "X_test, Y_test = split_dataset(data_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for i, (inputs, labels) in enumerate(data_loader_train):\n",
    "#     print(f\"Batch {i}:\")\n",
    "#     print(\"Inputs:\", inputs.shape)\n",
    "#     print(\"Labels:\",labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU()\n",
      "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (9): Flatten(start_dim=1, end_dim=-1)\n",
      "  (10): Linear(in_features=2304, out_features=128, bias=True)\n",
      "  (11): ReLU()\n",
      "  (12): Linear(in_features=128, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model 1 definition\n",
    "\n",
    "def Model1():\n",
    "    model = nn.Sequential(\n",
    "        # Convolutional layer 1\n",
    "        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        # Convolutional layer 2\n",
    "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        # Convolutional layer 3\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        # Flatten the output for fully connected layers\n",
    "        nn.Flatten(),\n",
    "\n",
    "        # Fully connected layers\n",
    "        nn.Linear(64 * 6 * 6, 128),  # Adjust the input size based on the output size of the previous layer\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 7)  # Adjust the output size based on the number of classes in your classificationÂ task\n",
    "    )\n",
    "\n",
    "    # Print the model architecture\n",
    "    print(model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 1.6732652420987\n",
      "Epoch [2/3], Loss: 1.4482483279731597\n",
      "Epoch [3/3], Loss: 1.3360286968322532\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, training_data_loader, validation_data_loader):\n",
    "    # Move model and data to GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model1.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 3\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in training_data_loader:\n",
    "\n",
    "            #this shoul be added only if running in GPU, otherwise comment\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(data_loader_train)}\")\n",
    "\n",
    "    # Example model class name extraction and save\n",
    "    model_class_name = model.__class__.__name__\n",
    "    filename = f'{model_class_name}_weights.pth'\n",
    "    torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model1, data_loader_train, data_loader_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Model1()\n",
    "\n",
    "model_class_name = model1.__class__.__name__\n",
    "filename = f'{model_class_name}_weights.pth'\n",
    "model1.load_state_dict(torch.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (inputs, labels) in enumerate(data_loader_test):\n",
    "#     print(f\"Batch {i}:\")\n",
    "#     # print(\"Inputs:\", inputs.shape)\n",
    "#     print(\"Labels:\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.4873223900794983\n"
     ]
    }
   ],
   "source": [
    "# evaluate model at end of epoch\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    acc = 0\n",
    "    count = 0\n",
    "    for pred, test in zip(y_pred, Y_test):\n",
    "        acc += (torch.argmax(pred) == test).float()\n",
    "        count+=1\n",
    "    acc = acc/count    \n",
    "    print(f\"Accuracy is {acc}\")\n",
    "\n",
    "    # print(y_pred.shape)\n",
    "    # print(Y_test.shape)\n",
    "    # print(y_pred[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model1, X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
